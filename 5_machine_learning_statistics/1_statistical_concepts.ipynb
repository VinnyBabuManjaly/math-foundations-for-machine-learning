{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb02dcaa",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Statistics is a foundational pillar of machine learning, providing essential tools for data understanding, uncertainty quantification, and reliable model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8fa22",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics\n",
    "\n",
    "Descriptive statistics are used to describe and summarize dataset features, helping to uncover patterns, outliers, and distributions early in ML projects. Key measures include:\n",
    "\n",
    "- Mean (average): The sum of all values divided by the number of values.\n",
    "\n",
    "- Median: The middle value in a sorted dataset (splits the data in half).\n",
    "\n",
    "- Mode: The value that appears most frequently.\n",
    "\n",
    "- Variance: The average of the squared differences from the mean — shows how spread out the data is.\n",
    "\n",
    "- Standard deviation: The square root of variance, indicating typical distance from the mean.\n",
    "\n",
    "- Range: Difference between max and min values.\n",
    "\n",
    "- Interquartile range (IQR): Spread of the middle 50% of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312c841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.471960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Values\n",
       "count  6.000000\n",
       "mean   2.833333\n",
       "std    1.471960\n",
       "min    1.000000\n",
       "25%    2.000000\n",
       "50%    2.500000\n",
       "75%    3.750000\n",
       "max    5.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [1, 2, 2, 3, 4, 5]\n",
    "df = pd.DataFrame(data, columns=[\"Values\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19e2f5",
   "metadata": {},
   "source": [
    "#### Inferential Statistics\n",
    "\n",
    "Inferential statistics allow us to make generalizations or predictions about an entire population based on a sample. Common techniques:\n",
    "\n",
    "- Hypothesis testing: Determines if sample results are likely for the population or just due to chance.\n",
    "\n",
    "- Confidence intervals: Estimate a range likely containing the population parameter.\n",
    "\n",
    "- Regression analysis: Models relationships between variables (see below).\n",
    "\n",
    "Python libraries like scipy.stats and statsmodels offer built-in functions for t-tests, confidence intervals, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373301e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.6742346141747673, P-value: 0.021311641128756727\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Compares means of two groups to see if they are statistically different\n",
    "# Here we compare two small sample groups\n",
    "# t_stat: measures the size of the difference relative to the variation in the sample data\n",
    "# p_value: probability of observing the data if the null hypothesis is true\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind([1,2,3], [4,5,6])\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# A low p-value (< 0.05) indicates strong evidence against the null hypothesis\n",
    "# Here we use two small sample groups for demonstration\n",
    "# In practice, use larger samples for reliable results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242cecb",
   "metadata": {},
   "source": [
    "#### Probability Theory\n",
    "\n",
    "Probability quantifies uncertainty in data and models. ML relies on:\n",
    "\n",
    "- Random variables: Variables whose values are outcomes of a random phenomenon.\n",
    "\n",
    "- Probability distributions: Functions like the normal (Gaussian) or binomial distributions that model the probability of outcomes.\n",
    "\n",
    "- Bayes' theorem: Updates probability estimates based on new evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c21dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of getting exactly 2 heads in 3 tosses: 0.375\n"
     ]
    }
   ],
   "source": [
    "# probability of getting heads in 3 coin tosses:\n",
    "\n",
    "from math import comb\n",
    "p = 0.5\n",
    "prob_2_heads = comb(3,2) * (p**2) * ((1-p)**1)  # Binomial probability\n",
    "print(f\"Probability of getting exactly 2 heads in 3 tosses: {prob_2_heads}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f87a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of z < 1.96: 0.9750021048517795\n"
     ]
    }
   ],
   "source": [
    "# For normal distribution:\n",
    "\n",
    "from scipy.stats import norm\n",
    "prob = norm.cdf(1.96)  # Probability value below z=1.96\n",
    "print(f\"Probability of z < 1.96: {prob}\")  # Should be close to 0.975"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72027a6",
   "metadata": {},
   "source": [
    "#### Sampling Techniques\n",
    "\n",
    "Sampling selects representative data from a population, which is crucial as ML rarely uses entire populations.\n",
    "\n",
    "- Random sampling: Each data point has equal selection chance.\n",
    "\n",
    "- Stratified sampling: Keeps proportional distribution of key subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777a8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python (random, stratified) using sklearn:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[i] for i in range(10)])  # Features\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])  # Binary target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50907c43",
   "metadata": {},
   "source": [
    "#### Regression Analysis\n",
    "\n",
    "Regression models the relationship between variables–essential for prediction.\n",
    "\n",
    "- Linear regression: Predicts a continuous variable.\n",
    "\n",
    "- Logistic regression: Predicts categorical outcomes (classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2: 0.8260679098062556\n",
      "Logistic Regression Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "log_model = LogisticRegression().fit(X_train, y_train)\n",
    "print(f\"Linear Regression R^2: {model.score(X_test, y_test)}\")\n",
    "print(f\"Logistic Regression Accuracy: {log_model.score(X_test, y_test)}\")\n",
    "# Linear Regression R^2: 1.0\n",
    "# Logistic Regression Accuracy: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c60627",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "\n",
    "Used to check if observed differences in data are statistically significant.\n",
    "\n",
    "- Null hypothesis: No effect or difference (default assumption).\n",
    "\n",
    "- Alternative hypothesis: Contradicts null, asserting a real effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce83a6",
   "metadata": {},
   "source": [
    "#### Statistical Learning Theory\n",
    "\n",
    "This underpins the mathematical basis of machine learning—studying how well models generalize from training data to unseen data by focusing on:\n",
    "\n",
    "- Generalization: Model performance on new, unseen data.\n",
    "\n",
    "- Bias-variance tradeoff: Balancing model complexity and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources:\n",
    "# [1](https://www.clicdata.com/blog/statistics-for-machine-learning/)\n",
    "# [2](https://www.reddit.com/r/MLQuestions/comments/u6l4bn/how_to_learn_machine_learning_my_roadmap/)\n",
    "# [3](https://www.tutorialspoint.com/machine_learning/machine_learning_statistics.htm)\n",
    "# [4](https://www.youtube.com/watch?v=7eh4d6sabA0)\n",
    "# [5](https://www.simplilearn.com/what-is-descriptive-statistics-article)\n",
    "# [6](https://www.machinelearningmastery.com/machine-learning-in-python-step-by-step/)\n",
    "# [7](https://www.geeksforgeeks.org/data-science/descriptive-statistic/)\n",
    "# [8](https://www.nrigroupindia.com/e-book/Introduction%20to%20Machine%20Learning%20with%20Python%20(%20PDFDrive.com%20)-min.pdf)\n",
    "# [9](https://builtin.com/data-science/intro-descriptive-statistics)\n",
    "# [10](https://www.youtube.com/watch?v=c8W7dRPdIPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
